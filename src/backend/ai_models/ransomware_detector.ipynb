{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile src/backend/ml_models/ransomware_detector.ipynb\n",
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Ransomware Detection System\\n\",\n",
    "    \"## Hybrid Deep Learning Model with Behavioral Analysis\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import tensorflow as tf\\n\",\n",
    "    \"from tensorflow.keras import layers, models\\n\",\n",
    "    \"from sklearn.ensemble import IsolationForest\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"from sklearn.metrics import classification_report, confusion_matrix\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"from tqdm import tqdm\\n\",\n",
    "    \"import hashlib\\n\",\n",
    "    \"import lief  # For PE file analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Configuration\\n\",\n",
    "    \"RANDOM_SEED = 42\\n\",\n",
    "    \"np.random.seed(RANDOM_SEED)\\n\",\n",
    "    \"tf.random.set_seed(RANDOM_SEED)\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Data Loading & Feature Engineering\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def load_and_process_data(file_path):\\n\",\n",
    "    \"    \\\"\\\"\\\"Load and process ransomware dataset\\\"\\\"\\\"\\n\",\n",
    "    \"    df = pd.read_csv(file_path)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Feature engineering\\n\",\n",
    "    \"    df['entropy'] = df['file_content'].apply(lambda x: calculate_entropy(x))\\n\",\n",
    "    \"    df['api_calls_per_sec'] = df['api_call_count'] / df['process_duration']\\n\",\n",
    "    \"    df['file_entropy_variance'] = df.groupby('process_id')['entropy'].transform('var')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Behavioral features\\n\",\n",
    "    \"    df['encryption_pattern'] = df.apply(detect_encryption_patterns, axis=1)\\n\",\n",
    "    \"    df['ransom_note_keywords'] = df['created_files'].apply(find_ransom_note_keywords)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return df\\n\",\n",
    "    \"\\n\",\n",
    "    \"def calculate_entropy(data):\\n\",\n",
    "    \"    \\\"\\\"\\\"Calculate Shannon entropy for file content\\\"\\\"\\\"\\n\",\n",
    "    \"    if isinstance(data, str):\\n\",\n",
    "    \"        data = data.encode()\\n\",\n",
    "    \"    counts = np.bincount(np.frombuffer(data, dtype=np.uint8))\\n\",\n",
    "    \"    probabilities = counts / len(data)\\n\",\n",
    "    \"    return -np.sum(probabilities * np.log2(probabilities + 1e-9))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Load dataset\\n\",\n",
    "    \"data = load_and_process_data(\\\"data/raw/ransomware_dataset.csv\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Hybrid Model Architecture\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def build_hybrid_model(input_shape):\\n\",\n",
    "    \"    \\\"\\\"\\\"Create LSTM + CNN hybrid model\\\"\\\"\\\"\\n\",\n",
    "    \"    inputs = layers.Input(shape=input_shape)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Temporal features branch\\n\",\n",
    "    \"    lstm_branch = layers.LSTM(128, return_sequences=True)(inputs)\\n\",\n",
    "    \"    lstm_branch = layers.LSTM(64)(lstm_branch)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Static features branch\\n\",\n",
    "    \"    static_branch = layers.Conv1D(64, 3, activation='relu')(inputs)\\n\",\n",
    "    \"    static_branch = layers.MaxPooling1D(2)(static_branch)\\n\",\n",
    "    \"    static_branch = layers.Flatten()(static_branch)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    combined = layers.concatenate([lstm_branch, static_branch])\\n\",\n",
    "    \"    dense = layers.Dense(64, activation='relu')(combined)\\n\",\n",
    "    \"    output = layers.Dense(1, activation='sigmoid')(dense)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    model = models.Model(inputs=inputs, outputs=output)\\n\",\n",
    "    \"    model.compile(\\n\",\n",
    "    \"        optimizer='adam',\\n\",\n",
    "    \"        loss='binary_crossentropy',\\n\",\n",
    "    \"        metrics=[\\n\",\n",
    "    \"            tf.keras.metrics.Precision(name='precision'),\\n\",\n",
    "    \"            tf.keras.metrics.Recall(name='recall'),\\n\",\n",
    "    \"            tf.keras.metrics.AUC(name='auc')\\n\",\n",
    "    \"        ]\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    return model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 3. Anomaly Detection Layer\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"class AnomalyAwareLayer(layers.Layer):\\n\",\n",
    "    \"    \\\"\\\"\\\"Custom layer combining ML model output with anomaly scores\\\"\\\"\\\"\\n\",\n",
    "    \"    def __init__(self, isolation_forest, **kwargs):\\n\",\n",
    "    \"        super().__init__(**kwargs)\\n\",\n",
    "    \"        self.isolation_forest = isolation_forest\\n\",\n",
    "    \"\\n\",\n",
    "    \"    def call(self, inputs):\\n\",\n",
    "    \"        ml_score, features = inputs\\n\",\n",
    "    \"        anomaly_score = self.isolation_forest.decision_function(features)\\n\",\n",
    "    \"        combined_score = ml_score * (1 - anomaly_score)\\n\",\n",
    "    \"        return combined_score\\n\",\n",
    "    \"\\n\",\n",
    "    \"def create_ensemble_model(hybrid_model, isolation_forest, feature_columns):\\n\",\n",
    "    \"    \\\"\\\"\\\"Create final ensemble model\\\"\\\"\\\"\\n\",\n",
    "    \"    feature_input = layers.Input(shape=(len(feature_columns),)\\n\",\n",
    "    \"    sequence_input = layers.Input(shape=hybrid_model.input_shape[1:])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    ml_output = hybrid_model(sequence_input)\\n\",\n",
    "    \"    anomaly_layer = AnomalyAwareLayer(isolation_forest)([ml_output, feature_input])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    model = models.Model(\\n\",\n",
    "    \"        inputs=[sequence_input, feature_input],\\n\",\n",
    "    \"        outputs=anomaly_layer\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    return model\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 4. Training Pipeline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Data preparation\\n\",\n",
    "    \"X_sequence = np.array(data['behavior_sequence'].tolist())\\n\",\n",
    "    \"X_features = data[['entropy', 'api_calls_per_sec', 'file_entropy_variance']]\\n\",\n",
    "    \"y = data['is_ransomware']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train-test split\\n\",\n",
    "    \"X_train_seq, X_test_seq, X_train_feat, X_test_feat, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X_sequence, X_features, y, test_size=0.2, stratify=y\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train Isolation Forest\\n\",\n",
    "    \"iso_forest = IsolationForest(contamination=0.1, random_state=RANDOM_SEED)\\n\",\n",
    "    \"iso_forest.fit(X_train_feat)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Build and train hybrid model\\n\",\n",
    "    \"model = build_hybrid_model(X_train_seq.shape[1:])\\n\",\n",
    "    \"history = model.fit(\\n\",\n",
    "    \"    X_train_seq,\\n\",\n",
    "    \"    y_train,\\n\",\n",
    "    \"    validation_split=0.1,\\n\",\n",
    "    \"    epochs=20,\\n\",\n",
    "    \"    batch_size=64,\\n\",\n",
    "    \"    class_weight={0: 1, 1: 5}  # Handle class imbalance\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create ensemble model\\n\",\n",
    "    \"final_model = create_ensemble_model(model, iso_forest, X_features.columns)\\n\",\n",
    "    \"final_model.compile(loss='binary_crossentropy', optimizer='adam')\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 5. Evaluation & Explainability\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Model evaluation\\n\",\n",
    "    \"y_pred = final_model.predict([X_test_seq, X_test_feat])\\n\",\n",
    "    \"y_pred_binary = (y_pred > 0.7).astype(int)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Classification Report:\\\")\\n\",\n",
    "    \"print(classification_report(y_test, y_pred_binary))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Confusion matrix\\n\",\n",
    "    \"cm = confusion_matrix(y_test, y_pred_binary)\\n\",\n",
    "    \"sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\\n\",\n",
    "    \"plt.xlabel('Predicted')\\n\",\n",
    "    \"plt.ylabel('Actual')\\n\",\n",
    "    \"plt.show()\\n\",\n",
    "    \"\\n\",\n",
    "    \"# SHAP explainability\\n\",\n",
    "    \"import shap\\n\",\n",
    "    \"explainer = shap.DeepExplainer(model, X_train_seq[:100])\\n\",\n",
    "    \"shap_values = explainer.shap_values(X_test_seq[:10])\\n\",\n",
    "    \"shap.initjs()\\n\",\n",
    "    \"shap.force_plot(explainer.expected_value[0], shap_values[0][0], X_test_seq[0])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 6. Real-time Detection\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"def real_time_detection(process_data):\\n\",\n",
    "    \"    \\\"\\\"\\\"Real-time ransomware detection pipeline\\\"\\\"\\\"\\n\",\n",
    "    \"    # Feature extraction\\n\",\n",
    "    \"    features = extract_live_features(process_data)\\n\",\n",
    "    \"    sequence = preprocess_sequence(process_data['behavior_log'])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Prediction\\n\",\n",
    "    \"    score = final_model.predict([np.array([sequence]), np.array([features])])[0][0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Alerting\\n\",\n",
    "    \"    if score > 0.85:\\n\",\n",
    "    \"        trigger_incident_response(process_data)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    return {\\n\",\n",
    "    \"        'score': float(score),\\n\",\n",
    "    \"        'features': features,\\n\",\n",
    "    \"        'timestamp': pd.Timestamp.now().isoformat()\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Example usage\\n\",\n",
    "    \"sample_process = {\\n\",\n",
    "    \"    'behavior_log': [...]  # Raw behavioral data\\n\",\n",
    "    \"}\\n\",\n",
    "    \"print(real_time_detection(sample_process))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 7. Model Persistence\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save models\\n\",\n",
    "    \"final_model.save(\\\"models/ransomware_detector.keras\\\")\\n\",\n",
    "    \"joblib.dump(iso_forest, \\\"models/anomaly_detector.pkl\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save feature engineering pipeline\\n\",\n",
    "    \"joblib.dump({\\n\",\n",
    "    \"    'feature_columns': X_features.columns.tolist(),\\n\",\n",
    "    \"    'preprocessor': preprocessor\\n\",\n",
    "    \"}, \\\"models/feature_pipeline.pkl\\\")\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.8.5\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key Features:\n",
    "\n",
    "Hybrid LSTM + CNN architecture for temporal/spatial pattern detection\n",
    "\n",
    "Integrated Isolation Forest for anomaly scoring\n",
    "\n",
    "Custom TensorFlow layer combining ML and anomaly scores\n",
    "\n",
    "Real-time behavioral analysis pipeline\n",
    "\n",
    "SHAP explainability for model decisions\n",
    "\n",
    "Automated incident response triggering\n",
    "\n",
    "Feature engineering for encryption patterns/entropy analysis\n",
    "\n",
    "Class imbalance handling with weighted loss\n",
    "\n",
    "Model persistence with full pipeline saving\n",
    "\n",
    "Comprehensive evaluation metrics"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
